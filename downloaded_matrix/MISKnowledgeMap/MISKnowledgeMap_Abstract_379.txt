The use of formative measurement in the field of Information Systems has increased, arguably due to statistical tools (e.g., PLS) that can test such models. However, in the literature, there exist two contradictory views on the potential deficiency of formative measurement. While opponents who are critical of formative measurement argue that there are native weaknesses of the formative approach in model estimation, proponents who are in favor of using formative measurement counter that opponents research methods in measurement model specification are flawed. The goal of this work is to empirically test these opposing views on whether the alleged estimation instability of formative measurement is due to measurement model misspecification or simply the shortcoming of formative measurement. To assess the integrity of arguments of both parties, we adopt a research design in which four different cases are tested in terms of interpretational confounding and external consistency. We find that regardless of whether there is a specification issue, formative measures can lead to misleading outcomes. Based on the results, we offer guidelines that researchers may adopt in planning and executing data analysis with structural equation modeling. Given that the use of formative measurement is at a critical juncture in the IS field, we believe that the guidelines in this research note are important to promote appropriate use of the approach rather than relegate it to a bandwagon effect.
