An increasing number of studies have appeared that evaluate and rank journal quality and the productivity of IS scholars and their institutions. In this paper, we describe the results of one recent study identifying the 'Top 30' IS Researchers, revealing many unexamined assumptions about which IS publication outlets should be included in any definition of high- quality, scholarly IS journals. Drawing from the argument that all categories and classification schemes are grounded in politics, we critique the process by which the recent study in question ( and several earlier studies) have derived the set of journals from which they count researcher publications. Based on a critical examination of the widespread inclusion of practitioner outlets, and the consistent exclusion of European scholarly IS journals, we develop our own arguments for which journals should be included in such evaluations of researcher productivity. We conduct our own analysis of IS researcher productivity for the period 1999 - 2003, based on articles published in a geographically balanced set of 12 IS journals, and then we compare our results with those from the recent study in question and their predecessors. Our results feature a more diverse set of scholars - both in terms of location ( specifically, the country and continent in which the researchers are employed) and gender. We urge future studies of IS research productivity to follow our practice of including high- quality European journals, while eschewing practitioner-oriented publications ( such as Harvard Business Review and Communications of the ACM). We also advocate that such studies count only research contributions ( e. g., research articles), and that other genres of non- research articles - such as book reviews, ` issues and opinions' pieces and editorial introductions - not be conflated with counts of research contributions.
